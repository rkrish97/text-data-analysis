{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECS189L HW4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHOzEL0C6pdJ",
        "outputId": "c6faaa73-6802-4bb2-a793-4e102c97a12b"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# load the data\n",
        "pd.set_option('display.max_rows', None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5fEXHPqItwW"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/lkyin/ECS189L/main/Tweets.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4dzP5357uec"
      },
      "source": [
        "def clean_data(text):\n",
        "  text = text.split()\n",
        "  #other_stop = [\"flights\",\"flight\", \"get\", \"plane\"]\n",
        "  for i in range(len(text)):\n",
        "    if text[i]!='':\n",
        "      text[i] = text[i].lower()\n",
        "      text[i] = text[i].strip()\n",
        "      if text[i][0]==\"@\" or text[i] in stopwords.words('english'):\n",
        "        text[i] = \"\"\n",
        "      text[i] = re.sub(r'[^\\w\\s]', '', text[i])\n",
        "      text[i] = re.sub('\\d+', '', text[i])\n",
        "      '''\n",
        "      for stop in other_stop:\n",
        "        text[i] = text[i].replace(stop, '')\n",
        "      '''\n",
        "  text2 = \" \".join(text)\n",
        "  return text2\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x:clean_data(str(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOY4uGtTJEGu",
        "outputId": "c4b885f0-d9f6-4f3b-d459-480ca759bd30"
      },
      "source": [
        "pos_df = pd.DataFrame(df[df['airline_sentiment']==\"positive\"]['text'])\n",
        "neg_df = pd.DataFrame(df[df['airline_sentiment']==\"negative\"]['text'])\n",
        "neut_df = pd.DataFrame(df[df['airline_sentiment']==\"neutral\"]['text'])\n",
        "print(\"top 10 most frequent words in positive sentiment class: \")\n",
        "print(pos_df.text.str.split(expand=True).stack().value_counts()[:10])\n",
        "print(\"top 10 most frequent words in negative sentiment class: \")\n",
        "print(neg_df.text.str.split(expand=True).stack().value_counts()[:10])\n",
        "print(\"top 10 most frequent words in neutral sentiment class: \")\n",
        "print(neut_df.text.str.split(expand=True).stack().value_counts()[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "top 10 most frequent words in positive sentiment class: \n",
            "thanks      609\n",
            "thank       453\n",
            "flight      375\n",
            "you         261\n",
            "great       233\n",
            "service     160\n",
            "love        132\n",
            "get         114\n",
            "customer    113\n",
            "guys        111\n",
            "dtype: int64\n",
            "top 10 most frequent words in negative sentiment class: \n",
            "flight       2918\n",
            "get           984\n",
            "cancelled     920\n",
            "service       742\n",
            "hours         653\n",
            "help          610\n",
            "hold          608\n",
            "customer      604\n",
            "time          584\n",
            "im            547\n",
            "dtype: int64\n",
            "top 10 most frequent words in neutral sentiment class: \n",
            "flight     602\n",
            "get        238\n",
            "please     179\n",
            "flights    167\n",
            "help       163\n",
            "need       163\n",
            "thanks     154\n",
            "im         136\n",
            "would      122\n",
            "dm         121\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsBqQZOROYiy",
        "outputId": "50611971-a3e6-49dc-a210-9c2f855cfc8a"
      },
      "source": [
        "df['text'] = df['text'].apply(lambda x:word_tokenize(x))\n",
        "ps = PorterStemmer()\n",
        "for ind, row in enumerate(df['text']):\n",
        "  stem_dict = {}\n",
        "  for i in range(len(row)):\n",
        "    new_stem = ps.stem(row[i])\n",
        "    if new_stem in stem_dict:\n",
        "      continue\n",
        "    else:\n",
        "      stem_dict[new_stem] = True\n",
        "  row_list = list(stem_dict.keys())\n",
        "  df['text'].iloc[ind] = \" \".join(row_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05njL8e60DdB",
        "outputId": "7a8834d4-64eb-47e8-e236-06b2722fcdb5"
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "tweet_list = df['text'].tolist()\n",
        "X = vectorizer.fit_transform(tweet_list)\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(X,df['airline_sentiment'].tolist(), test_size=0.2, random_state = 17) #seed=8, 17 best\n",
        "params = {\"max_depth\" : range(1,200, 10)}\n",
        "clf = GridSearchCV(DecisionTreeClassifier(), params,n_jobs=-1,scoring=\"accuracy\", cv=4)\n",
        "clf.fit(train_X, train_Y)\n",
        "clf = clf.best_estimator_\n",
        "print(\"Accuracy of the best model on test data: \",clf.score(test_X, test_Y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the best model on test data:  0.7223360655737705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqptkTEv_gGF",
        "outputId": "a23e5a9a-a309-4365-d92c-a2f7a74e32ff"
      },
      "source": [
        "pos_df = pd.DataFrame(df[df['airline_sentiment']==\"positive\"])\n",
        "neg_df = pd.DataFrame(df[df['airline_sentiment']==\"negative\"])\n",
        "neut_df = pd.DataFrame(df[df['airline_sentiment']==\"neutral\"])\n",
        "pos_airlines = pos_df['airline'].value_counts().keys().tolist()\n",
        "pos_counts = pos_df['airline'].value_counts().tolist()\n",
        "neg_airlines = neg_df['airline'].value_counts().keys().tolist()\n",
        "neg_counts = neg_df['airline'].value_counts().tolist()\n",
        "tot_airlines = df['airline'].value_counts().keys().tolist()\n",
        "tot_counts = df['airline'].value_counts().tolist()\n",
        "pos_dict = {}\n",
        "neg_dict = {}\n",
        "for i in range(len(tot_airlines)):\n",
        "  ind_pos = pos_airlines.index(tot_airlines[i])\n",
        "  ind_neg = neg_airlines.index(tot_airlines[i])\n",
        "  pos_frac = pos_counts[ind_pos]/tot_counts[i]\n",
        "  neg_frac = neg_counts[ind_pos]/tot_counts[i]\n",
        "  pos_dict[tot_airlines[i]] = pos_frac\n",
        "  neg_dict[tot_airlines[i]] = neg_frac\n",
        "\n",
        "print(\"Ranking of airline based on fraction of positive tweets: \",sorted(pos_dict, key=lambda x: pos_dict[x], reverse=True)[:3])\n",
        "print(\"Ranking of airline based on fraction of negative tweets: \",sorted(neg_dict, key=lambda x: neg_dict[x], reverse=True)[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ranking of airline based on fraction of positive tweets:  ['Virgin America', 'Delta', 'Southwest']\n",
            "Ranking of airline based on fraction of negative tweets:  ['Southwest', 'Delta', 'United']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}